<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Artificial Intelligence on Juan Lebrero</title><link>https://juanlebrero.com/categories/artificial-intelligence/</link><description>Recent content in Artificial Intelligence on Juan Lebrero</description><generator>Hugo</generator><language>en</language><lastBuildDate>Tue, 30 Dec 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://juanlebrero.com/categories/artificial-intelligence/index.xml" rel="self" type="application/rss+xml"/><item><title>From Local to Global: A Deep Dive into GraphRAG</title><link>https://juanlebrero.com/posts/graph-rag/</link><pubDate>Tue, 30 Dec 2025 00:00:00 +0000</pubDate><guid>https://juanlebrero.com/posts/graph-rag/</guid><description>&lt;p&gt;RAG (&lt;em&gt;Retrieval-Augmented Generation&lt;/em&gt;) has established itself as the industry standard for mitigating hallucinations in Large Language Models (LLMs) by injecting reliable data during response generation. The mechanism is well-known: given a query, the system retrieves relevant text fragments (&amp;ldquo;chunks&amp;rdquo;) from a vector database and passes them as context to the model to formulate a grounded answer. This approach involves retrieving specific data points for targeted questions. However, its performance degrades significantly when the task requires a transversal understanding of an entire corpus, such as answering &lt;em&gt;&amp;ldquo;What are the patterns of technological evolution in these 10,000 reports?&amp;rdquo;&lt;/em&gt;. Vector similarity retrieval, by delivering isolated pieces, lacks the architecture necessary to synthesize a global overview.&lt;/p&gt;</description></item></channel></rss>