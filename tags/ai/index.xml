<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on Juan Lebrero</title><link>https://juanlebrero.com/tags/ai/</link><description>Recent content in AI on Juan Lebrero</description><generator>Hugo</generator><language>en</language><lastBuildDate>Fri, 02 Jan 2026 00:00:00 +0000</lastBuildDate><atom:link href="https://juanlebrero.com/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>LightRAG: The Evolution of Graph-Based RAG Systems</title><link>https://juanlebrero.com/posts/light-rag/</link><pubDate>Fri, 02 Jan 2026 00:00:00 +0000</pubDate><guid>https://juanlebrero.com/posts/light-rag/</guid><description>&lt;p&gt;A few weeks ago I wrote about &lt;a href="https://juanlebrero.com/en/posts/graph-rag/"&gt;GraphRAG&lt;/a&gt; and how it changed the way we think about information retrieval using knowledge graphs. It was a huge advancement because it stopped relying exclusively on finding similar text and started understanding implicit relationships between entities.&lt;/p&gt;
&lt;p&gt;But after implementing it and using it in projects, I encountered some friction points. The most obvious one is having to choose between &amp;ldquo;Local&amp;rdquo; mode and &amp;ldquo;Global&amp;rdquo; mode before making a query. That works well in theory, but in practice it forces you to think: &amp;ldquo;Does this question need specific detail or broad synthesis?&amp;rdquo; And the answer is often &amp;ldquo;both,&amp;rdquo; which leaves you with a design problem.&lt;/p&gt;</description></item><item><title>From Local to Global: A Deep Dive into GraphRAG</title><link>https://juanlebrero.com/posts/graph-rag/</link><pubDate>Tue, 30 Dec 2025 00:00:00 +0000</pubDate><guid>https://juanlebrero.com/posts/graph-rag/</guid><description>&lt;p&gt;RAG (&lt;em&gt;Retrieval-Augmented Generation&lt;/em&gt;) has established itself as the industry standard for mitigating hallucinations in Large Language Models (LLMs) by injecting reliable data during response generation. The mechanism is well-known: given a query, the system retrieves relevant text fragments (&amp;ldquo;chunks&amp;rdquo;) from a vector database and passes them as context to the model to formulate a grounded answer. This approach involves retrieving specific data points for targeted questions. However, its performance degrades significantly when the task requires a transversal understanding of an entire corpus, such as answering &lt;em&gt;&amp;ldquo;What are the patterns of technological evolution in these 10,000 reports?&amp;rdquo;&lt;/em&gt;. Vector similarity retrieval, by delivering isolated pieces, lacks the architecture necessary to synthesize a global overview.&lt;/p&gt;</description></item></channel></rss>